{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300343fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n1. Neural Network and Activation Function\\n'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Neural Network and Activation Function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "240b8535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0333,  0.3738],\n",
      "        [ 0.0583,  0.3696],\n",
      "        [-0.0028,  0.4307]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# linear = nn.Linear(in_features, out_features)\n",
    "linear = nn.Linear(32,2)\n",
    "inputs = torch.rand(3,32)\n",
    "outputs = linear(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b58dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5083, 0.5924],\n",
      "        [0.5146, 0.5914],\n",
      "        [0.4993, 0.6061]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "activation  = F.sigmoid(outputs)\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb45e292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4157, 0.5843],\n",
      "        [0.4228, 0.5772],\n",
      "        [0.3933, 0.6067]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "activation = F.softmax(outputs, dim=1)\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d97ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0333, 0.3738],\n",
      "        [0.0583, 0.3696],\n",
      "        [0.0000, 0.4307]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "activation = F.relu(outputs)\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bec359f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2369, 0.7631],\n",
      "        [0.3061, 0.6939],\n",
      "        [0.2948, 0.7052]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. Constumed Neural Network Model\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\"\"\"\n",
    "Key: (1) Evlate a subclass from class Module of torch.nn\n",
    "     (2) access constructor & forward\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_class):\n",
    "        super(MLP, self).__init__() # linear transformation\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activate = F.relu\n",
    "        self.linear2 = nn.Linear(hidden_dim, num_class)\n",
    "    def forward(self, inputs):\n",
    "        hidden = self.linear1(inputs)\n",
    "        activation = self.activate(hidden)\n",
    "        outputs = self.linear2(activation)\n",
    "        probs = F.softmax(outputs,dim=1)\n",
    "        return probs\n",
    "mlp = MLP(input_dim=4,hidden_dim=5, num_class= 2)\n",
    "inputs = torch.rand(3,4)\n",
    "probs = mlp(inputs)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "131410f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-6f055472",
   "language": "python",
   "display_name": "PyCharm (NLP_BasedOnPretrainedModel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}